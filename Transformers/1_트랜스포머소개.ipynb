{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머를 활용한 자연어 처리\n",
    "# Chapter 1. 트랜스포머 소개\n",
    "- 시퀀스 모델링(sequence modeling)을 위한 새로운 신경망 아키텍처\n",
    "- 기계 번역 작업의 품질과 훈련 비용 면에서 순환 신경망(RNN)을 능가\n",
    "- 효율적인 전이 학습(transfer learning) 방법인 ULMFiT가 매우 크고 다양한 말뭉치(corpus)에서 LSTM 신경망을 훈련해 매우 적은 양의 레이블링된 데이터로도 최고 수준의 텍스트 분류 모델을 만들어냄을 증명\n",
    "- 트랜스포머 아키텍처와 비지도 학습(unsupervised learning)을 결합\n",
    "  - GPT (Generative Pretrained Transformer)\n",
    "  - BERT (Bidirectional Encoder Representation from Transformers)\n",
    "\n",
    "## 트랜스포머의 새로운 점\n",
    "1. 인코더-디코더 (encoder-decoder) 프레임워크\n",
    "2. 어텐션 매커니즘 (attention mechanism)\n",
    "3. 전이 학습 (transfer learning)\n",
    "\n",
    "## 1.1 인코더-디코더 프레임워크\n",
    "- 트랜스포머 등장 이전, NLP에서는 LSTM 같은 순환 신경망 구조가 최고 수준의 성능을 달성\n",
    "- 피드백 루프가, 텍스트와 같은 순차 데이터를 모델링하는 데 이상적\n",
    "- RNN의 경우, 네트워크를 통과시킨 후 은닉상태(hidden state)라는 벡터를 출력함과 동시에, 출력된 정보를 피드백 루프로 보내 자기 자신에 다시 입력\n",
    "- RNN은 출력한 정보의 일부를 다음 스텝에 사용\n",
    "- 이전 스텝의 정보를 추적하고 이를 사용해 예측을 만듬\n",
    "- 위와 같은 구조는, 인코더-디코더 또는 시퀀스-투-시퀀스(sequence-to-sequence) 구조로 처리하며 입력과 출력이 임의의 길이를 가진 시퀀스일 때 잘 맞음\n",
    "- 인코더는 입력 시퀀스의 정보를 마지막 은닉 상태(last hidden state)라고도 부르는 수치 표현으로 인코딩 -> 디코더로 전달되어 출력 시퀀스가 생성\n",
    "- 인코더의 마지막 은닉 상태가 정보 병목(information bottleneck)이 된다는 약점이 있음\n",
    "- 디코더가 인코더의 모든 은닉 상태에 접근해 병목 현상을 제거 -> 어텐션(attention) 메커니즘\n",
    "\n",
    "## 1.2 어텐션 메커니즘\n",
    "- 입력 시퀀스에서 은닉 상태를 만들지 않고 스텝마다 인코더에서 디코더가 참고할 은닉 상태를 출력한다는 주요 개념에 기초\n",
    "- 어떤 상태를 디코더가 먼저 사용할지 우선순위를 정하는 메커니즘이 필요\n",
    "- 디코더가 모든 디코딩 타임스탭마다 인코더의 각 상태에 다른 가중치 또는 어텐션을 할당\n",
    "- 계산이 순차적으로 수행되며, 입력 시퀀스 전체에 걸쳐 병렬화할 수 없음\n",
    "- 트랜스포머는, 순환을 모두 없애고 **셀프 어텐션(self-attention)**이라는 특별한 형태의 어텐션에 전적으로 의지\n",
    "  - 신경망의 같은 층에 있는 모든 상태에 대해서 어텐션을 작동시키는 방식\n",
    "- 어텐션의 출력은 FF NN에 주입\n",
    "\n",
    "## 1.3 NLP의 전이 학습\n",
    "- 비전 분야의 경우, 전이 학습을 사용해 한 작업에서 훈련한 다음 새로운 작업에 적용하거나 미세 튜닝(fine-tuning)하는 일이 많음\n",
    "- 신경망은, 원래 작업에서 학습한 지식을 사용\n",
    "- 모델은 구조적으로 바디와 헤드로 나눌 수 있음\n",
    "  - 바디: 훈련하는 동안 원래 도메인에서 다양한 특성을 학습하고, 이 가중치를 사용해 새로운 작업을 위한 모델을 초기화\n",
    "- 전통적인 지도 학습(supervised learning)과 비교하면, 전이 학습은 일반적으로 다양한 작업에서 적은 양의 레이블 데이터로 훨씬 효과적으로 훈련하는 높은 품질의 모델을 만듬\n",
    "\n",
    "### ULMFiT\n",
    "- OpenAI 연구원들이, 비지도 사전 훈련에서 추출한 특성을 사용해 높은 성능을 얻음\n",
    "- 다양한 작업에서 사전 훈련된 LSTM 모델을 적용\n",
    "\n",
    "#### 사전 훈련\n",
    "- 이전 단어를 바탕으로 다음 단어를 예측 (언어 모델링, language modeling)\n",
    "\n",
    "#### 도메인 적응\n",
    "- 언어 모델은 대규모 corpus(말뭉치)를 훈련하고, 도메인 내 corpus에 적응 시킴\n",
    "\n",
    "#### 미세튜닝\n",
    "- 언어 모델을 타깃 작업을 위한 분류 층과 함께 미세 튜닝\n",
    "\n",
    "### GPT\n",
    "- 트랜스포머의 아키텍처의 디코더 부분만 사용하고 ULMFiT 같은 언어 모델링 방법을 사용\n",
    "\n",
    "### BERT\n",
    "- 트랜스포머의 아키텍처의 인코더 부분만 사용하고 마스크드 언어 모델링(masked language modeling)이라는 특별한 형태의 언어 모델링을 사용\n",
    "  - 텍스트에서 랜덤하게 마스킹 된 단어를 예측\n",
    "\n",
    "## 1.4 허깅페이스 트랜스포머\n",
    "- 새로운 머신러닝 아키텍처를 새로운 작업에 적용하는 일은, 일반저긍로 다음 단계를 거침\n",
    "  - 1. 모델 아키텍처 구현\n",
    "  - 2. 훈련된 가중치 로드\n",
    "  - 3. 입력을 전처리하고 모델에 전달\n",
    "  - 4. 데이터로더를 구현하고 모델 훈련을 위해 손실 함수와 옵티마이저를 정의\n",
    "\n",
    "## 1.5 트랜스포머 애플리케이션 둘러보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \\\n",
    "\"\"\"\n",
    "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany.\n",
    "Unfortunately, when I opened the package, I discovered to my horro that I had been sent an action figure of Megatron instead!\n",
    "As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
    "Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 텍스트 분류\n",
    "- 원시 텍스트를 미세 튜닝된 모델의 예측으로 변환하기 위해 필요한 모든 단계를 추상화하는 파이프라인을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# pipeline 함수를 호출하면서 관심 작업 이름을 전달\n",
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text=classification`은 감정 분석을 위해 설계된 모델이지만, 다중 분류(multiclass classification)와 다중 레이블 분류도 지원 (multilabel classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outputs = classifier(text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 개체명 인식\n",
    "- NLP에서는 제품, 장소, 사람 같은 실제 객체를 **개체명(named entity)**이라 하고 이런 개체명을 텍스트에서 추출하는 작업을 **개체명 인식(named entity recognition (NER))**이라 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.874225</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.991447</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>Germany</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.581595</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.586276</td>\n",
       "      <td>Decept</td>\n",
       "      <td>253</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.516828</td>\n",
       "      <td>##icons</td>\n",
       "      <td>259</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.783311</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>350</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>367</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.810855</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>502</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.874225         Amazon      6   12\n",
       "1         MISC  0.991447  Optimus Prime     37   50\n",
       "2          LOC  0.999759        Germany     91   98\n",
       "3         MISC  0.581595           Mega    208  212\n",
       "4          PER  0.537129         ##tron    212  216\n",
       "5          ORG  0.586276         Decept    253  259\n",
       "6         MISC  0.516828        ##icons    259  264\n",
       "7         MISC  0.783311       Megatron    350  358\n",
       "8         MISC  0.988451  Optimus Prime    367  380\n",
       "9          PER  0.810855      Bumblebee    502  511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "outputs = ner_tagger(text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 질문 답변\n",
    "- 텍스트 구절과 함께 답을 얻고 싶은 질문을 모델에 전달하고, 모델은 답변 텍스트를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610561</td>\n",
       "      <td>335</td>\n",
       "      <td>358</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.610561    335  358  an exchange of Megatron"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = pipeline(\"question-answering\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4 요약\n",
    "- 텍스트 요약(text summarization)의 목표는 긴 텍스트를 입력으로 받고 관련 사실이 모두 포함된 간단한 버전을 생성하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee demands an exchange of Megatron for the Optimus Prime figure he ordered. The Decepticons figure was sent to a German online store instead of a Decepticon figure. The Autobot is a lifelong enemy of the Deceptacons and a lifelong foe\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "outputs = summarizer(text, max_length=56, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(outputs[0][\"summary_text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.5 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f53f95f728449ccb644319bf7785fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\huggingface_hub-0.13.1-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\spec3\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88904fc841b045929d7138043ca45722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2345c612a89f4efd86b15ff9dfa93651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Amazon, letzte Woche habe ich eine Optimus Prime Action Figur von Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Horror, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich hoffe, dass Sie mein Dilemma verstehen können. Um das Problem zu lösen, fordere ich einen Austausch von Megatron für die Optimus Prime Figur, die ich bestellt hatte. Eingeschlossen sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, bald von Ihnen zu hören. Aufrichtig, Bumblebee.\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "\n",
    "print(outputs[0][\"translation_text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.6 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cae5f8cff3d44e699ba831e74c5bd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4650d9d6d8a4cbe9ccb74f77429fd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e796fe60c4fc78bbec3b40c31e026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1396bad7d4b4337a81f1ebd844629a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c07fc77f6849b5b8c46e788bc9d51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943c637a6fa74f5aa0eb24a5708f2914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\transformers\\generation\\utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany.\n",
      "Unfortunately, when I opened the package, I discovered to my horro that I had been sent an action figure of Megatron instead!\n",
      "As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
      "Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
      "\n",
      "\n",
      "Customer service response:\n",
      "Dear Bumblebee, I am sorry to hear that your order was mixed up. My question was about 1 (a) Megatron, and (b) you do not need to buy the Transformers figure from Amazon.\n",
      "I ordered this from Amazon in Germany for my family, but their delivery date was in Germany at the time of my order.\n",
      "As an aside, you are not my\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 허깅페이스 생태계\n",
    "- 크게, 라이브러리와 허브로 구성\n",
    "  - 라이브러리는 코드를 제공\n",
    "  - 허브는 사전 훈련된 모델 가중치, 데이터셋, 평가 지표를 위한 스크립트 등을 제공\n",
    "\n",
    "### 1.6.1 허깅페이스 허브\n",
    "- 허브는, 모델과 데이터셋 내용을 문서화한 모델 카드와 데이터셋 카드를 제공\n",
    "\n",
    "### 1.6.2 허깅페이스 토크나이저\n",
    "- 트랜스포머 모델은 이런 토큰의 수치 표현에서 훈련\n",
    "- 다양한 토큰화 전력을 제공\n",
    "- 러스트(Rust) 백엔드 덕분에 빠른 속도\n",
    "\n",
    "### 1.6.3 허깅페이스 데이터셋\n",
    "- 수천 개의 데이터셋에 대한 표준 인터페이스를 제공해 단순화\n",
    "- 메모리 매핑(memory mapping)이라는 특별한 메커니즘을 활용해 램 부족을 피함\n",
    "  - 파일 내용을 가상 메모리에 저장하고 여러 개의 프로세스로 더 효율적으로 파일을 수정\n",
    "  - 데이터 랭글링(data wrangling) 도구를 그대로 사용 가능\n",
    "\n",
    "### 1.6.4 허깅페이스 액셀러레이트\n",
    "- 사용자 정의 로직을 처리하는 일반적인 훈련 루프에 훈련 인프라에 필요한 추상화 층을 추가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
