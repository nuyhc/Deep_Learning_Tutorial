{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow and PyTorch Setup\n",
    "- CUDA: 11.2\n",
    "- cuDNN : 8.6\n",
    "- TF: tensorflow==2.10.1\n",
    "- Torch: `conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch`\n",
    "- Python: 3.7.9\n",
    "\n",
    "### CUDA Setup\n",
    "- C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin\n",
    "- C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\lib\n",
    "- C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\include\n",
    "- `nvcc --version`\n",
    "- `nvidia-smi`\n",
    "\n",
    "### Ref\n",
    "[Tensorflow CUDA 버전 확인](https://www.tensorflow.org/install/source_windows)  \n",
    "[PyTorch 버전 확인](https://pytorch.org/get-started/previous-versions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3571914208852834554,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 14053015552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16429436950123834166\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUDA'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch GPU\n",
    "\"CUDA\" if torch.cuda.is_available() else \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 687us/step - loss: 0.2992 - accuracy: 0.9126\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 0.1450 - accuracy: 0.9570\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.1082 - accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 0.0876 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.0763 - accuracy: 0.9760\n",
      "313/313 - 0s - loss: 0.0777 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07766376435756683, 0.9758999943733215]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF GPU Use\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "99 665.2333984375\n",
      "199 473.0482177734375\n",
      "299 337.1463317871094\n",
      "399 241.0374298095703\n",
      "499 173.067626953125\n",
      "599 124.9959487915039\n",
      "699 90.99603271484375\n",
      "799 66.94786071777344\n",
      "899 49.93804168701172\n",
      "999 37.9062385559082\n",
      "1099 29.395362854003906\n",
      "1199 23.374919891357422\n",
      "1299 19.116058349609375\n",
      "1399 16.103254318237305\n",
      "1499 13.971904754638672\n",
      "1599 12.46407699584961\n",
      "1699 11.397354125976562\n",
      "1799 10.64267349243164\n",
      "1899 10.108749389648438\n",
      "1999 9.730995178222656\n",
      "Result: y = -0.03195663541555405 + 0.858229398727417 x + 0.005513053387403488 x^2 + -0.09354212880134583 x^3\n"
     ]
    }
   ],
   "source": [
    "# Torch GPU Use\n",
    "import math\n",
    "\n",
    "print(torch.__version__) # torch version 출력\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\") # Uncomment this to run on GPU, GPU 를 사용하므로 해당 라인 실행\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f0991e49adad1753eef4fa4b55232b676ddb958fe2380cbc7c0c4d0c1f50553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
