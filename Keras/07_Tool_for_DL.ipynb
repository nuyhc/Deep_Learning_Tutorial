{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 위한 고급 도구\n",
    "\n",
    "## 케라스의 함수형 API\n",
    "`Sequential` 모델은 네트워크 입력과 출력이 하나라고 가정  \n",
    "-> 층을 차례대로 쌓아 구성\n",
    "\n",
    "\n",
    "다양한 입력 소스에서 전달된 데이터를 다른 종류의 신경망 층을 사용해 처리해 합치는 경우도 있음  \n",
    "-> 각 모델을 따로 훈련해, 각 예측을 가중 평균(weighted average)을 해 사용 (각 모델에서 추출한 정보가 중복된다면 최적의 방법은 아님)  \n",
    "\n",
    "#### 최근 개발된 신경만 구조\n",
    "선형적이지 않은 네트워크 토폴로지(topology)를 갖음  \n",
    "- 인셉션(inception) 모듈\n",
    "- 잔차 연결 추가 (ex. ResNet 계열)\n",
    "  - 하위층(입력단)에서 학습된  정보가 데이터 처리 과정에서 손실되는 것을 방지\n",
    "\n",
    "### 함수형 API 소개\n",
    "함수형 API에서는 직접 텐서들의 입출력을 다룸  \n",
    "-> 함수처럼 층을 이용해 텐서를 입력 받고출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, )) # tensor\n",
    "dense = layers.Dense(32, activation=\"relu\") # 함수처럼 사용하기 위해 층 객체를 만듬\n",
    "\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from  tensorflow.keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation=\"relu\", input_shape=(64, )))\n",
    "seq_model.add(layers.Dense(32, activation=\"relu\"))\n",
    "seq_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수형 API로 만든 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(64, ))\n",
    "x = layers.Dense(32, activation=\"relu\")(input_tensor)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 입력 모델\n",
    "서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용 (텐서를 더하거나 이어 붙이는 식)  \n",
    "-> `keras.layers.add`, `keras.layers.concatenate` 등  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 다중 입력 모델 (질문-응답 (question-anwering) 모델)\n",
    "# input: 자연어 질문, 답변에 필요한 정보가 들어있는 텍스트\n",
    "# output: 답변 (미리 정의한 어휘 사전에서 softmax 함수를 통핸 한 단어를 선택)\n",
    "\n",
    "# 참고 텍스트 -> Embedding -> LSTM -> Concatenate -> Dense -> 응답\n",
    "#   질문     -> Embedding -> LSTM\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# 참고 텍스트\n",
    "text_input = Input(shape=(None, ), dtype=\"int32\", name=\"text\")\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "# 질문\n",
    "question_input = Input(shape=(None, ), dtype=\"int32\", name=\"question\")\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "# 참고 텍스트와 질문 연결\n",
    "concated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation=\"softmax\")(concated)\n",
    "\n",
    "model= Model([text_input, question_input],  answer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력이 2개인 모델을 훈련 시키는 방법\n",
    "1. 넘파이 배열 리스트 주입\n",
    "2. 입력 이름과 넘파이 배열로 이뤄진  딕셔너리 (입력 이름을 설정한 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length =100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question =np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "answer = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "\n",
    "answer = to_categorical(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 82ms/step - loss: 6.2146 - acc: 0.0040\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 6.1939 - acc: 0.0200\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 6.1207 - acc: 0.0070\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 6.0485 - acc: 0.0060\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 5.9923 - acc: 0.0090\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 5.9136 - acc: 0.0110\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 5.8197 - acc: 0.0140\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 5.7326 - acc: 0.0230\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 5.6506 - acc: 0.0250\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 5.5847 - acc: 0.0310\n"
     ]
    }
   ],
   "source": [
    "# 1. 넘파이 배열 리스트 주입\n",
    "with tf.device(\":/GPU:0\"):\n",
    "    model.fit([text, question], answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 79ms/step - loss: 6.2145 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 6.1966 - acc: 0.0480\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 6.1296 - acc: 0.0050\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 6.0548 - acc: 0.0090\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 5.9963 - acc: 0.0120\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 5.9311 - acc: 0.0150\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 5.8687 - acc: 0.0270\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 5.7692 - acc: 0.0280\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 5.6850 - acc: 0.0340\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 5.6090 - acc: 0.0320\n"
     ]
    }
   ],
   "source": [
    "# 2. 딕셔너리 형식으로 주입\n",
    "with tf.device(\":/GPU:0\"):\n",
    "    model.fit({\"text\":text, \"question\":question}, answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 출력 모델\n",
    "다중 입력과 동일하게, 함수형 API를 사용하면 다중 출력 모델을 만들  수  있음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터에 있는 여러 속성을 동시에 예측하는 네트워크\n",
    "# 소셜 미디어의 익명 사용자의 포스트 -> 나이, 성별, 소득 수준  등을 예측\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None, ), dtype=\"int32\", name=\"posts\")\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "age_pred = layers.Dense(1, name=\"age\")(x)\n",
    "income_pred = layers.Dense(num_income_groups, activation=\"softmax\",name=\"income\")(x)\n",
    "gender_pred = layers.Dense(1, activation=\"sigmoid\",  name=\"gender\")(x)\n",
    "\n",
    "model = Model(posts_input, [age_pred, income_pred, gender_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크 출력마다 다른 손실 함수를 지정해야 함  \n",
    "-> 경사 하강법은 하나의 스칼라 값을 최소화   \n",
    "-> 모든 손실을 하나의 값으로 합쳐야 함  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 콜백과 텐서보드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 튜닝: 성능 올리기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb2bcb1c2ebb90b367d5a8d04364bd69bb4cb2fbfe4a2e1d43ce6a6b227bb280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
