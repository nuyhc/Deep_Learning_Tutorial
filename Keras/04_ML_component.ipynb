{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신 러닝의 기본 요소\n",
    "## 머신 러닝의 네 가지 분류\n",
    "### 지도 학습 (Supervised Learning)\n",
    "샘플 데이터가 주어지면 알고 있는 타깃에 입력 데이터를 매핑하는 방법을 학습  \n",
    "대부분 분류와 회귀로 구성되지만 예외 사항도 있음  \n",
    "- 시퀀스 생성(sequence generation): 사진이 주어지면 이를 설명하는 캡션을 생성\n",
    "- 구문 트리(syntax tree) 예측: 문장이 주어지면 분해된 구문 트리를 예측\n",
    "- 물체 감지(object detection)\n",
    "- 이미지 분할(image segmentation)\n",
    "\n",
    "### 비지도 학습 (Unsupervised Learning)\n",
    "입력 데이터에 대한 흥미로운 변환을 찾음  \n",
    "- 차원축소(dimensionality reduction)\n",
    "- 군집(clustering)\n",
    "\n",
    "### 자기 지도 학습(Self-Supervised Learning)\n",
    "지도 학습의 특별한 경우이지만, 사람이 만든 레이블을 사용하지 않음  \n",
    "-> 학습 과정에서 사람이 개입하지 않음  \n",
    "-> 경험적인 알고리즘(heuristic algorithm)\n",
    "- 오토인코더(autoencoder)\n",
    "\n",
    "### 강화 학습(Reinforcement Learning)\n",
    "환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습\n",
    "\n",
    "## 머신러닝 모델 평가\n",
    "머신러닝의 목표는 처음 본 데이터에서 잘 작동하는 **일반화** 된 모델을 얻는 것\n",
    "### 훈련, 검증, 테스트 세트\n",
    "모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것  \n",
    "#### 정보 누설(Information Leak)\n",
    "검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것  \n",
    "-> 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것 -> 영향을 줌  \n",
    "- 홀드아웃 검증(hold-out validation)\n",
    "- K-겹 교차 검증(K-fold cross-validation)\n",
    "- 셔플링을 사용한 K-겹 교차 검증(iterated K-fold cross-validation)\n",
    "##### 홀드아웃 검증(hold-out validation)\n",
    "데이터의 일정량을 테스트 세트로 떼어 놓고, 남은 데이터에서 훈련하고 테스트 세트로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "# 검증 데이터\n",
    "validation_data = data[:num_validation_samples]\n",
    "# 훈련용 데이터\n",
    "data = data[num_validation_samples:]\n",
    "training_data = data[:]\n",
    "# 모델을 생성하고,\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# 모델 튜닝 진행 후,\n",
    "# 훈련과 평가 반복\n",
    "\n",
    "# 튜닝 종료후, 모든 데이터를 이용해 훈련을 다시 시킴\n",
    "model.train(np.concatenate([training_data, validation_data]))\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-겹 교차 검증(K-fold cross-validation)\n",
    "데이터를 동일한 크기를 가진 K개로 분할하고, 각 분할에 대해 K-1개로 훈련을하고 나머지로 검증을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_validation_samples = len(data)//4\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_score = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples*fold:num_validation_samples*(fold+1)]\n",
    "    training_data = data[:num_validation_samples*fold] + data[num_validation_samples*(fold+1):]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score.append(model.evaluate(validation_data))\n",
    "\n",
    "validation_score = np.average(validation_score)\n",
    "\n",
    "# 최종 훈련\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 셔플링을 사용한 반복 K-겹 교차 검증\n",
    "가용 데이터가 적고 가능한 정확하게 모델을 평가하고자하는 경우에 사용  \n",
    "K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞음 -> 최종 점수는 모든 평균 값\n",
    "\n",
    "## 데이터 전처리, 특성 공학, 특성 학습\n",
    "### 신경망을 위한 데이터 전처리\n",
    "데이터 전처리 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것  \n",
    "- 벡터화(vectorization)\n",
    "- 정규화(normalization)\n",
    "- 결측치 처리\n",
    "- 특성 추출\n",
    "\n",
    "## 과대적합과 과소적합\n",
    "머신러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다기  \n",
    "- 최적화(optimization): 가능한 훈련 데이터에서 최고 성능을 얻으려고 모델을 조정하는 과정\n",
    "- 일반화(generalization): 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지\n",
    "\n",
    "훈련 및 검증 데이터(한본 본 데이터)에서는 성능이 좋으나 테스트 데이터에서는 성능이 좋지 않음 -> 과대적합(overfitting)  \n",
    "훈련 및 검증 데이터, 테스트 데이터에서 모두 성능이 좋지 않음 -> 과소적합(underfitting)\n",
    "\n",
    "### 네트워크 크기 축소\n",
    "오버피팅을 막는 가장 단순한 방법\n",
    "\n",
    "### 가중치 규제(Weight Requlrization)\n",
    "오컴의 면도날(Occam's razor) -> 어떤 것에 대한 두 가지 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것이라는 이론  \n",
    "간단한 모델 -> 파라미터 값 분포의 엔트로피가 작은 모델 -> 과대적합을 완하하기 위한 일반적인 방법으로 모델 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 규제하는 것  \n",
    "- L1 규제: 가중치의 절대값에 비례하는 비용이 추가\n",
    "- L2 규제: 가중치의 제곱에 비례하는 비용이 추가, 가중치 감쇠(weight decay)라고도 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequence(sequence, dimension=10000):\n",
    "    result = np.zeros((len(sequence), dimension))\n",
    "    for i, sequence in enumerate(sequence):\n",
    "        result[i, sequence] = 1.\n",
    "    return result\n",
    "\n",
    "x_train = vectorize_sequence(train_data)\n",
    "x_test = vectorize_sequence(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "# 모델에 L2 규제 추가\n",
    "model.add(Dense(units=16, kernel_regularizer=L2(0.001), activation=\"relu\", input_shape=(10000, )))\n",
    "model.add(Dense(units=16, kernel_regularizer=L2(0.001)))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃(dropout)\n",
    "신경망을 위해 사용되는 규제 기법 중에서 가장 효과적이고 널리 사용되는 방법 중 하나  \n",
    "훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킴  \n",
    "-> 테스트 단계에서는 적용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# 모델에 드롭아웃 추가\n",
    "model.add(Dense(16, activation=\"relu\", input_shape=(10000, )))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 작업 흐름\n",
    "1. 문제 정의와 데이터 수집\n",
    "2. 지표 선택\n",
    "3. 평가 방법 선택\n",
    "4. 모델 생성\n",
    "5. 모델 규제와 하이퍼파라미터 튜닝\n",
    "\n",
    "|문제 유형|출력층 활성화 함수|손실함수|\n",
    "|------|---|---|\n",
    "|이진 분류|시그모이드|binary_crossentropy|\n",
    "|단일 레이블 다중 분류|소프트맥스|categorical_crossentropy|\n",
    "|다중 레이블 다중 분류|시그모이드|binary_crossentropy|\n",
    "|임의 값에 대한 회귀| |mse|\n",
    "|0과 1 사이 값에 대한 회귀|시그모이드|mse 또는 binary_crossentropy|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74cb2441972c5e2ce4d81cf164d964ef294956299a0f54ad32355ca0ab9e0fa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
